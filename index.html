<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="./img/favicon.ico">

	<title>Bayesian Data Fusion</title>

        <link href="./css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="./css/font-awesome-4.0.3.css" rel="stylesheet">
        <link href="./css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="./css/highlight.css">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        
    </head>

    <body class="homepage">

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            

            <!-- Main title -->
            <a class="navbar-brand" href=".">Bayesian Data Fusion</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                
                
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#bayesiandatafusionjl-package">BayesianDataFusion.jl package</a></li>
        
            <li><a href="#features">Features</a></li>
        
            <li><a href="#installation">Installation</a></li>
        
    
        <li class="main "><a href="#examples">Examples</a></li>
        
            <li><a href="#movielens">MovieLens</a></li>
        
            <li><a href="#movielens-wo-side-information">MovieLens w/o side-information</a></li>
        
            <li><a href="#tensor-factorization-with-side-information">Tensor factorization with side information</a></li>
        
            <li><a href="#multi-relational-models">Multi-relational models</a></li>
        
    
        <li class="main "><a href="#saving-latent-vectors">Saving latent vectors</a></li>
        
            <li><a href="#reading-latent-matrix-files">Reading latent matrix files</a></li>
        
            <li><a href="#saving-link-matrix-beta">Saving link matrix (beta)</a></li>
        
    
        <li class="main "><a href="#efficient-storage-of-sparse-matrices">Efficient storage of sparse matrices</a></li>
        
    
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="bayesiandatafusionjl-package">BayesianDataFusion.jl package</h1>
<p>This gives reference and examples for <a href="https://github.com/jaak-s/BayesianDataFusion.jl">BayesianDataFusion.jl</a>.</p>
<h2 id="features">Features</h2>
<p><code>BayesianDataFusion.jl</code> provides parallel and highly optimized implementation for</p>
<ul>
<li>Bayesian Probabilistic Matrix Factorization (BPMF)</li>
<li>Bayesian Probabilistic Tensor Factorization (BPTF)</li>
<li>Macau - Bayesian Multi-relational Factorization with Side Information</li>
</ul>
<p>These methods allow to predict <strong>unobserved values</strong> in the matrices (or tensors). Since they are all Bayesian methods we can also measure the <strong>uncertainty</strong> of the predictions. BPMF and BPTF are special cases of Macau. Macau adds</p>
<ul>
<li>use of <strong>entity side information</strong> to improve factorization (e.g, user and/or movie features for factorizing movie ratings)</li>
<li>use of <strong>relation side information</strong> to improve factorization  (e.g., data about when user went to see particular movie)</li>
<li>factorization of <strong>several</strong> matrices (and tensors) for an entity simultaneously.</li>
<li>Macau can handle high dimensional side-information, e.g., 1,000,000-dimensional user features.</li>
</ul>
<h2 id="installation">Installation</h2>
<p>Inside Julia:</p>
<pre><code class="julia">Pkg.clone(&quot;https://github.com/jaak-s/BayesianDataFusion.jl.git&quot;)
</code></pre>

<h1 id="examples">Examples</h1>
<p>Next we give simple examples of using <strong>Macau</strong> for movie ratings prediction from MovieLens data, which is included in the BayesianDataFusion package.</p>
<h2 id="movielens">MovieLens</h2>
<p>We will use <code>macau</code> function to factorize (incompletely observed) matrix of movie ratings with <strong>side information</strong> for both users and movies. The side information contains basic features about users like age group and gender and genre information for movies. To run the example first install Julia library for reading matlab files</p>
<pre><code class="julia">Pkg.add(&quot;MAT&quot;)
</code></pre>

<p>Example code</p>
<pre><code class="julia">using BayesianDataFusion
using MAT
## load and setup data
pkgdir = Pkg.dir(&quot;BayesianDataFusion&quot;)
data   = matread(&quot;$pkgdir/data/movielens_1m.mat&quot;)

## setup entities, assigning side information through optional argument F
users  = Entity(&quot;users&quot;,  F=data[&quot;Fu&quot;]);
movies = Entity(&quot;movies&quot;, F=data[&quot;Fv&quot;]);

## setup the relation between users and movies, data from sparse matrix data[&quot;X&quot;]
## first element in '[users, movies]' corresponds to rows and second to columns of data[&quot;X&quot;]
ratings = Relation(data[&quot;X&quot;], &quot;ratings&quot;, [users, movies], class_cut = 2.5);

## assign 500,000 of the observed ratings randomly to the test set
assignToTest!(ratings, 500_000)

## precision of the ratings to 1.5 (i.e., variance of 1/1.5)
setPrecision!(ratings, 1.5)

## the model (with only one relation)
RD = RelationData(ratings)

## run Gibbs sampler of Macau with 10 latent dimensions, total of 100 burnin and 400 posterior samples
result = macau(RD, burnin=100, psamples=400, clamp=[1.0, 5.0], num_latent=10)
</code></pre>

<p>This model has only a single relation <code>ratings</code> between entities <code>users</code> and <code>movies</code>.
We use precision 1.5, which is known to be a good estimate of movie rating noise.
The optional parameter <code>clamp=[1.0, 5.0]</code> to <code>macau</code> thresholds the predictions to be between 1.0 and 5.0.
To build a model with larger latent dimension use, for example, <code>num_latent=30</code>.</p>
<p>Macau output shows the progress of the Gibbs sampler:</p>
<pre><code>  1: Acc=0.836 ROC=0.500 RMSE=1.118 | use[U:  3.1 β:0.04 λ=21.] mov[U:  3.1 β:0.07 λ=10.] | rati[α=1.5] [4s]
  2: Acc=0.836 ROC=0.500 RMSE=1.118 | use[U:  4.4 β:0.03 λ=60.] mov[U:  4.4 β:0.04 λ=38.] | rati[α=1.5] [0s]
...
 80: Acc=0.864 ROC=0.829 RMSE=0.889 | use[U: 72.7 β:1.34 λ=4.5] mov[U:122.6 β:3.25 λ=3.1] | rati[α=1.5] [0s]
 81: Acc=0.864 ROC=0.829 RMSE=0.888 | use[U: 73.0 β:1.39 λ=5.3] mov[U:123.0 β:3.32 λ=3.2] | rati[α=1.5] [0s]
...
</code></pre>

<p>The Acc/ROC/RMSE are computed on the test ratings. Note the optional argument <code>class_cut = 2.5</code>, used for creating a <code>Relation</code>, defines the class boundary for computing accuracy (Acc) and AUC-ROC (ROC) values. </p>
<p>An example result of the run is:</p>
<pre><code>Dict{AbstractString,Any} with 10 entries:
  &quot;latent_multi_threading&quot; =&gt; true
  &quot;psamples&quot;               =&gt; 400
  &quot;lambda_beta&quot;            =&gt; 14.506891192240246
  &quot;RMSE&quot;                   =&gt; 0.8526296036293598
  &quot;train_counts&quot;           =&gt; 500000x2 DataFrames.DataFrame…
  &quot;predictions&quot;            =&gt; 500000x5 DataFrames.DataFrame…
  &quot;burnin&quot;                 =&gt; 100
  &quot;num_latent&quot;             =&gt; 10
  &quot;accuracy&quot;               =&gt; 0.870428
  &quot;ROC&quot;                    =&gt; 0.8485116969174835
</code></pre>

<p>where <code>result["predictions"]</code> gives predicted values and their standard deviation for the values in the test set. The <code>result</code> also contains ROC, RMSE and accuracy values for the test set.</p>
<h2 id="movielens-wo-side-information">MovieLens w/o side-information</h2>
<p>The above example used user and move features. You can easily factorize the ratings without them, which would correspond to classic <strong>BPMF</strong> method. Here is an example code</p>
<pre><code class="julia">using BayesianDataFusion
using MAT
## load and setup data
pkgdir = Pkg.dir(&quot;BayesianDataFusion&quot;)
data   = matread(&quot;$pkgdir/data/movielens_1m.mat&quot;)

## setup entities, no features (F):
users  = Entity(&quot;users&quot;);
movies = Entity(&quot;movies&quot;);

## setup the relation between users and movies, data from sparse matrix data[&quot;X&quot;]
## first element in '[users, movies]' corresponds to rows and second to columns of data[&quot;X&quot;]
ratings = Relation(data[&quot;X&quot;], &quot;ratings&quot;, [users, movies], class_cut = 2.5);

## assign 500,000 of the observed ratings randomly to the test set
assignToTest!(ratings, 500_000)

## precision of the ratings to 1.5 (i.e., variance of 1/1.5)
setPrecision!(ratings, 1.5)

## the model (with only one relation)
RD = RelationData(ratings)

## run Gibbs sampler of Macau with 10 latent dimensions, total of 100 burnin and 400 posterior samples
result = macau(RD, burnin=100, psamples=400, clamp=[1.0, 5.0], num_latent=10)
</code></pre>

<p>In most applications the performance of pure BPMF is weaker compared to Macau. This is also true in the case of MovieLens dataset.</p>
<h2 id="tensor-factorization-with-side-information">Tensor factorization with side information</h2>
<p>Here is an example of factorization of 3-tensor on a toy data of <code>compound x cell_line x gene</code> where two of the modes have side information. We first generate the toy dataset:</p>
<pre><code class="julia">using BayesianDataFusion
using DataFrames

## generating artificial data
Ncompounds = 100
Ncell_lines = 10
Ngenes      = 50

A = randn(Ncompounds,  2);
B = randn(Ncell_lines, 2);
C = randn(Ngenes, 2);

X = Float64[ sum(A[i,:].*B[j,:].*C[k,:]) for i in 1:size(A,1), j in 1:size(B,1), k in 1:size(C,1)];

## adding artificial data into DataFrame
df = DataFrame(compound=Int64[], cell_line=Int64[], gene=Int64[], value=Float64[])
for i=1:size(A,1), j=1:size(B,1), k=1:size(C,1)
  push!(df, Any[i, j, k, X[i,j,k]])
end

## generating side information
Fcompounds = A * randn(2, 5);
Fgenes = C * randn(2, 10);
</code></pre>

<p>The dataframe object has an id for each mode and the last column gives the value of the tensor.</p>
<pre><code>head(df)
6×4 DataFrames.DataFrame
│ Row │ compound │ cell_line │ gene │ value     │
├─────┼──────────┼───────────┼──────┼───────────┤
│ 1   │ 1        │ 1         │ 1    │ -0.112793 │
│ 2   │ 1        │ 1         │ 2    │ 0.555784  │
│ 3   │ 1        │ 1         │ 3    │ 0.116109  │
│ 4   │ 1        │ 1         │ 4    │ 0.106436  │
│ 5   │ 1        │ 1         │ 5    │ 0.661452  │
│ 6   │ 1        │ 1         │ 6    │ -0.483896 │
</code></pre>

<p>Next we set up the 3-tensor model and add side information to <code>compound</code> and <code>gene</code> data</p>
<pre><code class="julia">## creating the three entities (compounds and genes have side information)
compound  = Entity(&quot;compound&quot;, F = Fcompounds);
cell_line = Entity(&quot;cell_line&quot;);
gene      = Entity(&quot;gene&quot;, F = Fgenes);

## creating Tensor relation
gene_expr = Relation(df, &quot;GeneExpr&quot;, [compound, cell_line, gene], class_cut = 0.0)

## setting noise precision of the observations (1 / variance)
setPrecision!(gene_expr, 5.0)

## assign 5000 values to test set
assignToTest!(gene_expr, 5000)

## the model with one 3-tensor
RD = RelationData(gene_expr)

## perform factorization
result = macau(RD, burnin=100, psamples=900, num_latent=10)
</code></pre>

<p>The dataframe <code>result["predictions"]</code> gives the predictions on the test set.
For this toy dataset <code>num_latent=10</code> is sufficient, for larger datasets it should be increased.
The model we executed looks like this:</p>
<pre><code class="java">julia&gt; RD
[Relations]
  GeneExpr: compound--cell_line--gene, #known = 45000, #test = 5000, α = 5.00
[Entities]
  compound:    100 with 5 features (λ = sample)
 cell_line:     10 with no features
      gene:     50 with 10 features (λ = sample)
</code></pre>

<h2 id="multi-relational-models">Multi-relational models</h2>
<p>Macau also provides factorization of models with multiple relations, where each entity can have also side information.
Here is an example where we have 3 entities: <code>users</code>, <code>movies</code>, <code>books</code> with 2 relations <code>movie_ratings</code> and <code>book_ratings</code>.
For illustration we add side information on <code>movies</code> (8-dimensional) and <code>books</code> (12-dimensional).</p>
<pre><code class="julia">using BayesianDataFusion

## entities
Nusers  = 50
Nmovies = 25
Nbooks  = 20
users  = Entity(&quot;users&quot;)
movies = Entity(&quot;movies&quot;, F = randn(Nmovies, 8))  # side information
books  = Entity(&quot;books&quot;,  F = randn(Nbooks, 12))  # side information

## relations, using random data
movie_ratings = Relation(sprand(Nusers, Nmovies, 0.2), &quot;mratings&quot;, [users, movies], class_cut = 0.5)
book_ratings  = Relation(sprand(Nusers, Nbooks, 0.3), &quot;bratings&quot;, [users, books], class_cut = 0.5)

## assign 20 movie ratings to test set
assignToTest!(movie_ratings, 20)

## set precision of the observation noise (inverse of variance)
setPrecision!(movie_ratings, 1.5)
setPrecision!(book_ratings, 2.0)

## multi-relational model
RD = RelationData()
addRelation!(RD, movie_ratings)
addRelation!(RD, book_ratings)

## run Macau with 10 latent dimensions, total of 100 burnin and 400 posterior samples
result = macau(RD, burnin=100, psamples=400, num_latent=10)
</code></pre>

<p>Note that Macau reports RMSE on the test data of the first relation, which in this example was <code>movie_ratings</code>.
To see the model structure you can check the model (even before the run).</p>
<pre><code>julia&gt; RD
[Relations]
  mratings: users--movies, #known = 233, #test = 20, α = 1.50
  bratings: users--books, #known = 314, #test = 0, α = 2.00
[Entities]
     users:     50 with no features
    movies:     25 with 8 features (λ = sample)
     books:     20 with 12 features (λ = sample)
</code></pre>

<h1 id="saving-latent-vectors">Saving latent vectors</h1>
<p>To save the sampled latent variables to disk macau has <code>output</code> parameter. If it is set to non-empty string <code>macau</code> saves all posterior latent variable matrices and uses the <code>output</code> value as a prefix for the file names. The prefix can also include the path, for example</p>
<pre><code>result = macau(RD, output = &quot;/home/user/mylatent&quot;)
</code></pre>

<p>which will save the files as <code>/home/user/mylatent-...</code>.
Every sampled latent matrix of every entity will be saved as a separate file, stored by default in CSV format. There is also an option to save the output in binary 32bit floats (which will reduce the space required by 2x). This can be enabled by using <code>output_type="binary"</code>.</p>
<p>To save the files using prefix <code>mylatent</code> into the current working directory use <code>output = "mylatent"</code>.</p>
<h2 id="reading-latent-matrix-files">Reading latent matrix files</h2>
<p>The saved CSV files can be read by the standard <code>readdlm</code> function</p>
<pre><code class="julia">U1 = readdlm(&quot;mylatent-entity1-01.csv&quot;, ',')
</code></pre>

<p>where "01" is the sample number that takes values from "01" (or "001") to <code>psamples</code>.</p>
<p>If the <code>output_type="binary"</code> was used, the written files can be read by using the function <code>read_binary_float32</code>, for example</p>
<pre><code class="julia">using BayesianDataFusion
U1 = read_binary_float32(&quot;mylatent-entity1-01.binary&quot;)
</code></pre>

<h2 id="saving-link-matrix-beta">Saving link matrix (beta)</h2>
<p>For the models that have features the sampled link matrices <code>beta</code> can be saved by setting both <code>output</code> to a prefix and <code>output_beta = true</code>. For example:</p>
<pre><code>result = macau(RD, output = &quot;/home/user/mylatent&quot;, output_beta = true)
</code></pre>

<p>The beta matrices can be read similarly to the latent matrix files as described above, using either <code>readdlm</code> for CSV files and <code>read_binary_float32</code> for binary files.</p>
<h1 id="efficient-storage-of-sparse-matrices">Efficient storage of sparse matrices</h1>
<p>The package also includes functions for writing and reading binary format for <strong>sparse matrix</strong>.</p>
<pre><code class="julia">## random sparse matrix
X = sprand(100, 50, 0.1)
write_sparse_float32(&quot;X.sparse&quot;, X)

## reading back the rows, cols and values from the file
I, J, V = read_sparse_float32(&quot;X.sparse&quot;)
X2 = sparse(I, J, V)
</code></pre></div>
            
        </div>

        <footer class="col-md-12">
            <hr>
            
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>

        <script src="./js/jquery-1.10.2.min.js"></script>
        <script src="./js/bootstrap-3.0.3.min.js"></script>
        <script src="./js/highlight.pack.js"></script>
        <script>var base_url = '.';</script>
        <script data-main="./mkdocs/js/search.js" src="./mkdocs/js/require.js"></script>
        <script src="./js/base.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="modal-header">
                        <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                        <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                    </div>
                    <div class="modal-body">
                        <p>
                            From here you can search these documents. Enter
                            your search terms below.
                        </p>
                        <form role="form">
                            <div class="form-group">
                                <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                            </div>
                        </form>
                        <div id="mkdocs-search-results"></div>
                    </div>
                    <div class="modal-footer">
                    </div>
                </div>
            </div>
        </div>

    </body>
</html>

<!--
MkDocs version : 0.14.0
Build Date UTC : 2017-01-26 14:03:14.074424
-->
