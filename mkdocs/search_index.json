{
    "docs": [
        {
            "location": "/",
            "text": "BayesianDataFusion.jl package\n\n\nThis gives reference and examples for \nBayesianDataFusion.jl\n.\n\n\nFeatures\n\n\nBayesianDataFusion.jl\n provides parallel and highly optimized implementation for\n\n\n\n\nBayesian Probabilistic Matrix Factorization (BPMF)\n\n\nBayesian Probabilistic Tensor Factorization (BPTF)\n\n\nMacau - Bayesian Multi-relational Factorization with Side Information\n\n\n\n\nThese methods allow to predict \nunobserved values\n in the matrices (or tensors). Since they are all Bayesian methods we can also measure the \nuncertainty\n of the predictions. BPMF and BPTF are special cases of Macau. Macau adds\n\n\n\n\nuse of \nentity side information\n to improve factorization (e.g, user and/or movie features for factorizing movie ratings)\n\n\nuse of \nrelation side information\n to improve factorization  (e.g., data about when user went to see particular movie)\n\n\nfactorization of \nseveral\n matrices (and tensors) for an entity simultaneously.\n\n\nMacau can handle high dimensional side-information, e.g., 1,000,000-dimensional user features.\n\n\n\n\nInstallation\n\n\nInside Julia:\n\n\nPkg.clone(\"https://github.com/jaak-s/BayesianDataFusion.jl.git\")\n\n\n\n\nExamples\n\n\nNext we give simple examples of using \nMacau\n for movie ratings prediction from MovieLens data, which is included in the BayesianDataFusion package.\n\n\nMovieLens\n\n\nWe will use \nmacau\n function to factorize (incompletely observed) matrix of movie ratings with \nside information\n for both users and movies. The side information contains basic features about users like age group and gender and genre information for movies. To run the example first install Julia library for reading matlab files\n\n\nPkg.add(\"MAT\")\n\n\n\n\nExample code\n\n\nusing BayesianDataFusion\nusing MAT\n## load and setup data\npkgdir = Pkg.dir(\"BayesianDataFusion\")\ndata   = matread(\"$pkgdir/data/movielens_1m.mat\")\n\n## setup entities, assigning side information through optional argument F\nusers  = Entity(\"users\",  F=data[\"Fu\"]);\nmovies = Entity(\"movies\", F=data[\"Fv\"]);\n\n## setup the relation between users and movies, data from sparse matrix data[\"X\"]\n## first element in '[users, movies]' corresponds to rows and second to columns of data[\"X\"]\nratings = Relation(data[\"X\"], \"ratings\", [users, movies], class_cut = 2.5);\n\n## assign 500,000 of the observed ratings randomly to the test set\nassignToTest!(ratings, 500_000)\n\n## precision of the ratings to 1.5 (i.e., variance of 1/1.5)\nsetPrecision!(ratings, 1.5)\n\n## the model (with only one relation)\nRD = RelationData(ratings)\n\n## run Gibbs sampler of Macau with 10 latent dimensions, total of 100 burnin and 400 posterior samples\nresult = macau(RD, burnin=100, psamples=400, clamp=[1.0, 5.0], num_latent=10)\n\n\n\n\nThis model has only a single relation \nratings\n between entities \nusers\n and \nmovies\n.\nWe use precision 1.5, which is known to be a good estimate of movie rating noise.\nThe optional parameter \nclamp=[1.0, 5.0]\n to \nmacau\n thresholds the predictions to be between 1.0 and 5.0.\nTo build a model with larger latent dimension use, for example, \nnum_latent=30\n.\n\n\nMacau output shows the progress of the Gibbs sampler:\n\n\n  1: Acc=0.836 ROC=0.500 RMSE=1.118 | use[U:  3.1 \u03b2:0.04 \u03bb=21.] mov[U:  3.1 \u03b2:0.07 \u03bb=10.] | rati[\u03b1=1.5] [4s]\n  2: Acc=0.836 ROC=0.500 RMSE=1.118 | use[U:  4.4 \u03b2:0.03 \u03bb=60.] mov[U:  4.4 \u03b2:0.04 \u03bb=38.] | rati[\u03b1=1.5] [0s]\n...\n 80: Acc=0.864 ROC=0.829 RMSE=0.889 | use[U: 72.7 \u03b2:1.34 \u03bb=4.5] mov[U:122.6 \u03b2:3.25 \u03bb=3.1] | rati[\u03b1=1.5] [0s]\n 81: Acc=0.864 ROC=0.829 RMSE=0.888 | use[U: 73.0 \u03b2:1.39 \u03bb=5.3] mov[U:123.0 \u03b2:3.32 \u03bb=3.2] | rati[\u03b1=1.5] [0s]\n...\n\n\n\n\nThe Acc/ROC/RMSE are computed on the test ratings. Note the optional argument \nclass_cut = 2.5\n, used for creating a \nRelation\n, defines the class boundary for computing accuracy (Acc) and AUC-ROC (ROC) values. \n\n\nAn example result of the run is:\n\n\nDict{AbstractString,Any} with 10 entries:\n  \"latent_multi_threading\" => true\n  \"psamples\"               => 400\n  \"lambda_beta\"            => 14.506891192240246\n  \"RMSE\"                   => 0.8526296036293598\n  \"train_counts\"           => 500000x2 DataFrames.DataFrame\u2026\n  \"predictions\"            => 500000x5 DataFrames.DataFrame\u2026\n  \"burnin\"                 => 100\n  \"num_latent\"             => 10\n  \"accuracy\"               => 0.870428\n  \"ROC\"                    => 0.8485116969174835\n\n\n\n\nwhere \nresult[\"predictions\"]\n gives predicted values and their standard deviation for the values in the test set. The \nresult\n also contains ROC, RMSE and accuracy values for the test set.\n\n\nMovieLens w/o side-information\n\n\nThe above example used user and move features. You can easily factorize the ratings without them, which would correspond to classic \nBPMF\n method. Here is an example code\n\n\nusing BayesianDataFusion\nusing MAT\n## load and setup data\npkgdir = Pkg.dir(\"BayesianDataFusion\")\ndata   = matread(\"$pkgdir/data/movielens_1m.mat\")\n\n## setup entities, no features (F):\nusers  = Entity(\"users\");\nmovies = Entity(\"movies\");\n\n## setup the relation between users and movies, data from sparse matrix data[\"X\"]\n## first element in '[users, movies]' corresponds to rows and second to columns of data[\"X\"]\nratings = Relation(data[\"X\"], \"ratings\", [users, movies], class_cut = 2.5);\n\n## assign 500,000 of the observed ratings randomly to the test set\nassignToTest!(ratings, 500_000)\n\n## precision of the ratings to 1.5 (i.e., variance of 1/1.5)\nsetPrecision!(ratings, 1.5)\n\n## the model (with only one relation)\nRD = RelationData(ratings)\n\n## run Gibbs sampler of Macau with 10 latent dimensions, total of 100 burnin and 400 posterior samples\nresult = macau(RD, burnin=100, psamples=400, clamp=[1.0, 5.0], num_latent=10)\n\n\n\n\nIn most applications the performance of pure BPMF is weaker compared to Macau. This is also true in the case of MovieLens dataset.\n\n\nTensor factorization with side information\n\n\nHere is an example of factorization of 3-tensor on a toy data of \ncompound x cell_line x gene\n where two of the modes have side information. We first generate the toy dataset:\n\n\nusing BayesianDataFusion\nusing DataFrames\n\n## generating artificial data\nNcompounds = 100\nNcell_lines = 10\nNgenes      = 50\n\nA = randn(Ncompounds,  2);\nB = randn(Ncell_lines, 2);\nC = randn(Ngenes, 2);\n\nX = Float64[ sum(A[i,:].*B[j,:].*C[k,:]) for i in 1:size(A,1), j in 1:size(B,1), k in 1:size(C,1)];\n\n## adding artificial data into DataFrame\ndf = DataFrame(compound=Int64[], cell_line=Int64[], gene=Int64[], value=Float64[])\nfor i=1:size(A,1), j=1:size(B,1), k=1:size(C,1)\n  push!(df, Any[i, j, k, X[i,j,k]])\nend\n\n## generating side information\nFcompounds = A * randn(2, 5);\nFgenes = C * randn(2, 10);\n\n\n\n\nThe dataframe object has an id for each mode and the last column gives the value of the tensor.\n\n\nhead(df)\n6\u00d74 DataFrames.DataFrame\n\u2502 Row \u2502 compound \u2502 cell_line \u2502 gene \u2502 value     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 1        \u2502 1         \u2502 1    \u2502 -0.112793 \u2502\n\u2502 2   \u2502 1        \u2502 1         \u2502 2    \u2502 0.555784  \u2502\n\u2502 3   \u2502 1        \u2502 1         \u2502 3    \u2502 0.116109  \u2502\n\u2502 4   \u2502 1        \u2502 1         \u2502 4    \u2502 0.106436  \u2502\n\u2502 5   \u2502 1        \u2502 1         \u2502 5    \u2502 0.661452  \u2502\n\u2502 6   \u2502 1        \u2502 1         \u2502 6    \u2502 -0.483896 \u2502\n\n\n\n\nNext we set up the 3-tensor model and add side information to \ncompound\n and \ngene\n data\n\n\n## creating the three entities (compounds and genes have side information)\ncompound  = Entity(\"compound\", F = Fcompounds);\ncell_line = Entity(\"cell_line\");\ngene      = Entity(\"gene\", F = Fgenes);\n\n## creating Tensor relation\ngene_expr = Relation(df, \"GeneExpr\", [compound, cell_line, gene], class_cut = 0.0)\n\n## setting noise precision of the observations (1 / variance)\nsetPrecision!(gene_expr, 5.0)\n\n## assign 5000 values to test set\nassignToTest!(gene_expr, 5000)\n\n## the model with one 3-tensor\nRD = RelationData(gene_expr)\n\n## perform factorization\nresult = macau(RD, burnin=100, psamples=900, num_latent=10)\n\n\n\n\nThe dataframe \nresult[\"predictions\"]\n gives the predictions on the test set.\nFor this toy dataset \nnum_latent=10\n is sufficient, for larger datasets it should be increased.\nThe model we executed looks like this:\n\n\njulia> RD\n[Relations]\n  GeneExpr: compound--cell_line--gene, #known = 45000, #test = 5000, \u03b1 = 5.00\n[Entities]\n  compound:    100 with 5 features (\u03bb = sample)\n cell_line:     10 with no features\n      gene:     50 with 10 features (\u03bb = sample)\n\n\n\n\nMulti-relational models\n\n\nMacau also provides factorization of models with multiple relations, where each entity can have also side information.\nHere is an example where we have 3 entities: \nusers\n, \nmovies\n, \nbooks\n with 2 relations \nmovie_ratings\n and \nbook_ratings\n.\nFor illustration we add side information on \nmovies\n (8-dimensional) and \nbooks\n (12-dimensional).\n\n\nusing BayesianDataFusion\n\n## entities\nNusers  = 50\nNmovies = 25\nNbooks  = 20\nusers  = Entity(\"users\")\nmovies = Entity(\"movies\", F = randn(Nmovies, 8))  # side information\nbooks  = Entity(\"books\",  F = randn(Nbooks, 12))  # side information\n\n## relations, using random data\nmovie_ratings = Relation(sprand(Nusers, Nmovies, 0.2), \"mratings\", [users, movies], class_cut = 0.5)\nbook_ratings  = Relation(sprand(Nusers, Nbooks, 0.3), \"bratings\", [users, books], class_cut = 0.5)\n\n## assign 20 movie ratings to test set\nassignToTest!(movie_ratings, 20)\n\n## set precision of the observation noise (inverse of variance)\nsetPrecision!(movie_ratings, 1.5)\nsetPrecision!(book_ratings, 2.0)\n\n## multi-relational model\nRD = RelationData()\naddRelation!(RD, movie_ratings)\naddRelation!(RD, book_ratings)\n\n## run Macau with 10 latent dimensions, total of 100 burnin and 400 posterior samples\nresult = macau(RD, burnin=100, psamples=400, num_latent=10)\n\n\n\n\nNote that Macau reports RMSE on the test data of the first relation, which in this example was \nmovie_ratings\n.\nTo see the model structure you can check the model (even before the run).\n\n\njulia> RD\n[Relations]\n  mratings: users--movies, #known = 233, #test = 20, \u03b1 = 1.50\n  bratings: users--books, #known = 314, #test = 0, \u03b1 = 2.00\n[Entities]\n     users:     50 with no features\n    movies:     25 with 8 features (\u03bb = sample)\n     books:     20 with 12 features (\u03bb = sample)\n\n\n\n\nSaving latent vectors\n\n\nTo save the sampled latent variables to disk macau has \noutput\n parameter. If it is set to non-empty string \nmacau\n saves all posterior latent variable matrices and uses the \noutput\n value as a prefix for the file names. The prefix can also include the path, for example\n\n\nresult = macau(RD, output = \"/home/user/mylatent\")\n\n\n\n\nwhich will save the files as \n/home/user/mylatent-...\n.\nEvery sampled latent matrix of every entity will be saved as a separate file, stored by default in CSV format. There is also an option to save the output in binary 32bit floats (which will reduce the space required by 2x). This can be enabled by using \noutput_type=\"binary\"\n.\n\n\nTo save the files using prefix \nmylatent\n into the current working directory use \noutput = \"mylatent\"\n.\n\n\nReading latent matrix files\n\n\nThe saved CSV files can be read by the standard \nreaddlm\n function\n\n\nU1 = readdlm(\"mylatent-entity1-01.csv\", ',')\n\n\n\n\nwhere \"01\" is the sample number that takes values from \"01\" (or \"001\") to \npsamples\n.\n\n\nIf the \noutput_type=\"binary\"\n was used, the written files can be read by using the function \nread_binary_float32\n, for example\n\n\nusing BayesianDataFusion\nU1 = read_binary_float32(\"mylatent-entity1-01.binary\")\n\n\n\n\nSaving link matrix (beta)\n\n\nFor the models that have features the sampled link matrices \nbeta\n can be saved by setting both \noutput\n to a prefix and \noutput_beta = true\n. For example:\n\n\nresult = macau(RD, output = \"/home/user/mylatent\", output_beta = true)\n\n\n\n\nThe beta matrices can be read similarly to the latent matrix files as described above, using either \nreaddlm\n for CSV files and \nread_binary_float32\n for binary files.\n\n\nEfficient storage of sparse matrices\n\n\nThe package also includes functions for writing and reading binary format for \nsparse matrix\n.\n\n\n## random sparse matrix\nX = sprand(100, 50, 0.1)\nwrite_sparse_float32(\"X.sparse\", X)\n\n## reading back the rows, cols and values from the file\nI, J, V = read_sparse_float32(\"X.sparse\")\nX2 = sparse(I, J, V)",
            "title": "Home"
        },
        {
            "location": "/#bayesiandatafusionjl-package",
            "text": "This gives reference and examples for  BayesianDataFusion.jl .",
            "title": "BayesianDataFusion.jl package"
        },
        {
            "location": "/#features",
            "text": "BayesianDataFusion.jl  provides parallel and highly optimized implementation for   Bayesian Probabilistic Matrix Factorization (BPMF)  Bayesian Probabilistic Tensor Factorization (BPTF)  Macau - Bayesian Multi-relational Factorization with Side Information   These methods allow to predict  unobserved values  in the matrices (or tensors). Since they are all Bayesian methods we can also measure the  uncertainty  of the predictions. BPMF and BPTF are special cases of Macau. Macau adds   use of  entity side information  to improve factorization (e.g, user and/or movie features for factorizing movie ratings)  use of  relation side information  to improve factorization  (e.g., data about when user went to see particular movie)  factorization of  several  matrices (and tensors) for an entity simultaneously.  Macau can handle high dimensional side-information, e.g., 1,000,000-dimensional user features.",
            "title": "Features"
        },
        {
            "location": "/#installation",
            "text": "Inside Julia:  Pkg.clone(\"https://github.com/jaak-s/BayesianDataFusion.jl.git\")",
            "title": "Installation"
        },
        {
            "location": "/#examples",
            "text": "Next we give simple examples of using  Macau  for movie ratings prediction from MovieLens data, which is included in the BayesianDataFusion package.",
            "title": "Examples"
        },
        {
            "location": "/#movielens",
            "text": "We will use  macau  function to factorize (incompletely observed) matrix of movie ratings with  side information  for both users and movies. The side information contains basic features about users like age group and gender and genre information for movies. To run the example first install Julia library for reading matlab files  Pkg.add(\"MAT\")  Example code  using BayesianDataFusion\nusing MAT\n## load and setup data\npkgdir = Pkg.dir(\"BayesianDataFusion\")\ndata   = matread(\"$pkgdir/data/movielens_1m.mat\")\n\n## setup entities, assigning side information through optional argument F\nusers  = Entity(\"users\",  F=data[\"Fu\"]);\nmovies = Entity(\"movies\", F=data[\"Fv\"]);\n\n## setup the relation between users and movies, data from sparse matrix data[\"X\"]\n## first element in '[users, movies]' corresponds to rows and second to columns of data[\"X\"]\nratings = Relation(data[\"X\"], \"ratings\", [users, movies], class_cut = 2.5);\n\n## assign 500,000 of the observed ratings randomly to the test set\nassignToTest!(ratings, 500_000)\n\n## precision of the ratings to 1.5 (i.e., variance of 1/1.5)\nsetPrecision!(ratings, 1.5)\n\n## the model (with only one relation)\nRD = RelationData(ratings)\n\n## run Gibbs sampler of Macau with 10 latent dimensions, total of 100 burnin and 400 posterior samples\nresult = macau(RD, burnin=100, psamples=400, clamp=[1.0, 5.0], num_latent=10)  This model has only a single relation  ratings  between entities  users  and  movies .\nWe use precision 1.5, which is known to be a good estimate of movie rating noise.\nThe optional parameter  clamp=[1.0, 5.0]  to  macau  thresholds the predictions to be between 1.0 and 5.0.\nTo build a model with larger latent dimension use, for example,  num_latent=30 .  Macau output shows the progress of the Gibbs sampler:    1: Acc=0.836 ROC=0.500 RMSE=1.118 | use[U:  3.1 \u03b2:0.04 \u03bb=21.] mov[U:  3.1 \u03b2:0.07 \u03bb=10.] | rati[\u03b1=1.5] [4s]\n  2: Acc=0.836 ROC=0.500 RMSE=1.118 | use[U:  4.4 \u03b2:0.03 \u03bb=60.] mov[U:  4.4 \u03b2:0.04 \u03bb=38.] | rati[\u03b1=1.5] [0s]\n...\n 80: Acc=0.864 ROC=0.829 RMSE=0.889 | use[U: 72.7 \u03b2:1.34 \u03bb=4.5] mov[U:122.6 \u03b2:3.25 \u03bb=3.1] | rati[\u03b1=1.5] [0s]\n 81: Acc=0.864 ROC=0.829 RMSE=0.888 | use[U: 73.0 \u03b2:1.39 \u03bb=5.3] mov[U:123.0 \u03b2:3.32 \u03bb=3.2] | rati[\u03b1=1.5] [0s]\n...  The Acc/ROC/RMSE are computed on the test ratings. Note the optional argument  class_cut = 2.5 , used for creating a  Relation , defines the class boundary for computing accuracy (Acc) and AUC-ROC (ROC) values.   An example result of the run is:  Dict{AbstractString,Any} with 10 entries:\n  \"latent_multi_threading\" => true\n  \"psamples\"               => 400\n  \"lambda_beta\"            => 14.506891192240246\n  \"RMSE\"                   => 0.8526296036293598\n  \"train_counts\"           => 500000x2 DataFrames.DataFrame\u2026\n  \"predictions\"            => 500000x5 DataFrames.DataFrame\u2026\n  \"burnin\"                 => 100\n  \"num_latent\"             => 10\n  \"accuracy\"               => 0.870428\n  \"ROC\"                    => 0.8485116969174835  where  result[\"predictions\"]  gives predicted values and their standard deviation for the values in the test set. The  result  also contains ROC, RMSE and accuracy values for the test set.",
            "title": "MovieLens"
        },
        {
            "location": "/#movielens-wo-side-information",
            "text": "The above example used user and move features. You can easily factorize the ratings without them, which would correspond to classic  BPMF  method. Here is an example code  using BayesianDataFusion\nusing MAT\n## load and setup data\npkgdir = Pkg.dir(\"BayesianDataFusion\")\ndata   = matread(\"$pkgdir/data/movielens_1m.mat\")\n\n## setup entities, no features (F):\nusers  = Entity(\"users\");\nmovies = Entity(\"movies\");\n\n## setup the relation between users and movies, data from sparse matrix data[\"X\"]\n## first element in '[users, movies]' corresponds to rows and second to columns of data[\"X\"]\nratings = Relation(data[\"X\"], \"ratings\", [users, movies], class_cut = 2.5);\n\n## assign 500,000 of the observed ratings randomly to the test set\nassignToTest!(ratings, 500_000)\n\n## precision of the ratings to 1.5 (i.e., variance of 1/1.5)\nsetPrecision!(ratings, 1.5)\n\n## the model (with only one relation)\nRD = RelationData(ratings)\n\n## run Gibbs sampler of Macau with 10 latent dimensions, total of 100 burnin and 400 posterior samples\nresult = macau(RD, burnin=100, psamples=400, clamp=[1.0, 5.0], num_latent=10)  In most applications the performance of pure BPMF is weaker compared to Macau. This is also true in the case of MovieLens dataset.",
            "title": "MovieLens w/o side-information"
        },
        {
            "location": "/#tensor-factorization-with-side-information",
            "text": "Here is an example of factorization of 3-tensor on a toy data of  compound x cell_line x gene  where two of the modes have side information. We first generate the toy dataset:  using BayesianDataFusion\nusing DataFrames\n\n## generating artificial data\nNcompounds = 100\nNcell_lines = 10\nNgenes      = 50\n\nA = randn(Ncompounds,  2);\nB = randn(Ncell_lines, 2);\nC = randn(Ngenes, 2);\n\nX = Float64[ sum(A[i,:].*B[j,:].*C[k,:]) for i in 1:size(A,1), j in 1:size(B,1), k in 1:size(C,1)];\n\n## adding artificial data into DataFrame\ndf = DataFrame(compound=Int64[], cell_line=Int64[], gene=Int64[], value=Float64[])\nfor i=1:size(A,1), j=1:size(B,1), k=1:size(C,1)\n  push!(df, Any[i, j, k, X[i,j,k]])\nend\n\n## generating side information\nFcompounds = A * randn(2, 5);\nFgenes = C * randn(2, 10);  The dataframe object has an id for each mode and the last column gives the value of the tensor.  head(df)\n6\u00d74 DataFrames.DataFrame\n\u2502 Row \u2502 compound \u2502 cell_line \u2502 gene \u2502 value     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1   \u2502 1        \u2502 1         \u2502 1    \u2502 -0.112793 \u2502\n\u2502 2   \u2502 1        \u2502 1         \u2502 2    \u2502 0.555784  \u2502\n\u2502 3   \u2502 1        \u2502 1         \u2502 3    \u2502 0.116109  \u2502\n\u2502 4   \u2502 1        \u2502 1         \u2502 4    \u2502 0.106436  \u2502\n\u2502 5   \u2502 1        \u2502 1         \u2502 5    \u2502 0.661452  \u2502\n\u2502 6   \u2502 1        \u2502 1         \u2502 6    \u2502 -0.483896 \u2502  Next we set up the 3-tensor model and add side information to  compound  and  gene  data  ## creating the three entities (compounds and genes have side information)\ncompound  = Entity(\"compound\", F = Fcompounds);\ncell_line = Entity(\"cell_line\");\ngene      = Entity(\"gene\", F = Fgenes);\n\n## creating Tensor relation\ngene_expr = Relation(df, \"GeneExpr\", [compound, cell_line, gene], class_cut = 0.0)\n\n## setting noise precision of the observations (1 / variance)\nsetPrecision!(gene_expr, 5.0)\n\n## assign 5000 values to test set\nassignToTest!(gene_expr, 5000)\n\n## the model with one 3-tensor\nRD = RelationData(gene_expr)\n\n## perform factorization\nresult = macau(RD, burnin=100, psamples=900, num_latent=10)  The dataframe  result[\"predictions\"]  gives the predictions on the test set.\nFor this toy dataset  num_latent=10  is sufficient, for larger datasets it should be increased.\nThe model we executed looks like this:  julia> RD\n[Relations]\n  GeneExpr: compound--cell_line--gene, #known = 45000, #test = 5000, \u03b1 = 5.00\n[Entities]\n  compound:    100 with 5 features (\u03bb = sample)\n cell_line:     10 with no features\n      gene:     50 with 10 features (\u03bb = sample)",
            "title": "Tensor factorization with side information"
        },
        {
            "location": "/#multi-relational-models",
            "text": "Macau also provides factorization of models with multiple relations, where each entity can have also side information.\nHere is an example where we have 3 entities:  users ,  movies ,  books  with 2 relations  movie_ratings  and  book_ratings .\nFor illustration we add side information on  movies  (8-dimensional) and  books  (12-dimensional).  using BayesianDataFusion\n\n## entities\nNusers  = 50\nNmovies = 25\nNbooks  = 20\nusers  = Entity(\"users\")\nmovies = Entity(\"movies\", F = randn(Nmovies, 8))  # side information\nbooks  = Entity(\"books\",  F = randn(Nbooks, 12))  # side information\n\n## relations, using random data\nmovie_ratings = Relation(sprand(Nusers, Nmovies, 0.2), \"mratings\", [users, movies], class_cut = 0.5)\nbook_ratings  = Relation(sprand(Nusers, Nbooks, 0.3), \"bratings\", [users, books], class_cut = 0.5)\n\n## assign 20 movie ratings to test set\nassignToTest!(movie_ratings, 20)\n\n## set precision of the observation noise (inverse of variance)\nsetPrecision!(movie_ratings, 1.5)\nsetPrecision!(book_ratings, 2.0)\n\n## multi-relational model\nRD = RelationData()\naddRelation!(RD, movie_ratings)\naddRelation!(RD, book_ratings)\n\n## run Macau with 10 latent dimensions, total of 100 burnin and 400 posterior samples\nresult = macau(RD, burnin=100, psamples=400, num_latent=10)  Note that Macau reports RMSE on the test data of the first relation, which in this example was  movie_ratings .\nTo see the model structure you can check the model (even before the run).  julia> RD\n[Relations]\n  mratings: users--movies, #known = 233, #test = 20, \u03b1 = 1.50\n  bratings: users--books, #known = 314, #test = 0, \u03b1 = 2.00\n[Entities]\n     users:     50 with no features\n    movies:     25 with 8 features (\u03bb = sample)\n     books:     20 with 12 features (\u03bb = sample)",
            "title": "Multi-relational models"
        },
        {
            "location": "/#saving-latent-vectors",
            "text": "To save the sampled latent variables to disk macau has  output  parameter. If it is set to non-empty string  macau  saves all posterior latent variable matrices and uses the  output  value as a prefix for the file names. The prefix can also include the path, for example  result = macau(RD, output = \"/home/user/mylatent\")  which will save the files as  /home/user/mylatent-... .\nEvery sampled latent matrix of every entity will be saved as a separate file, stored by default in CSV format. There is also an option to save the output in binary 32bit floats (which will reduce the space required by 2x). This can be enabled by using  output_type=\"binary\" .  To save the files using prefix  mylatent  into the current working directory use  output = \"mylatent\" .",
            "title": "Saving latent vectors"
        },
        {
            "location": "/#reading-latent-matrix-files",
            "text": "The saved CSV files can be read by the standard  readdlm  function  U1 = readdlm(\"mylatent-entity1-01.csv\", ',')  where \"01\" is the sample number that takes values from \"01\" (or \"001\") to  psamples .  If the  output_type=\"binary\"  was used, the written files can be read by using the function  read_binary_float32 , for example  using BayesianDataFusion\nU1 = read_binary_float32(\"mylatent-entity1-01.binary\")",
            "title": "Reading latent matrix files"
        },
        {
            "location": "/#saving-link-matrix-beta",
            "text": "For the models that have features the sampled link matrices  beta  can be saved by setting both  output  to a prefix and  output_beta = true . For example:  result = macau(RD, output = \"/home/user/mylatent\", output_beta = true)  The beta matrices can be read similarly to the latent matrix files as described above, using either  readdlm  for CSV files and  read_binary_float32  for binary files.",
            "title": "Saving link matrix (beta)"
        },
        {
            "location": "/#efficient-storage-of-sparse-matrices",
            "text": "The package also includes functions for writing and reading binary format for  sparse matrix .  ## random sparse matrix\nX = sprand(100, 50, 0.1)\nwrite_sparse_float32(\"X.sparse\", X)\n\n## reading back the rows, cols and values from the file\nI, J, V = read_sparse_float32(\"X.sparse\")\nX2 = sparse(I, J, V)",
            "title": "Efficient storage of sparse matrices"
        }
    ]
}